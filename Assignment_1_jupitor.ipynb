{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbC3DN7kqO4W",
        "outputId": "742a3c85-8673-463a-c55f-e8229f2b67b9"
      },
      "outputs": [],
      "source": [
        "# pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2KIvMgiqSTf"
      },
      "source": [
        "# Quetion 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "ftzmoerdq17U"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# import wandb\n",
        "from keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26yVpk3krjSf",
        "outputId": "2c6a2203-0163-42bb-c7f8-60c9b970e9d9"
      },
      "outputs": [],
      "source": [
        "# !wandb login 494428cc53b5c21da594f4fc75035d136c63a93c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "Fa57qwwHrn3U",
        "outputId": "508d1c83-59b6-45f4-fdf3-12765e1a3de2"
      },
      "outputs": [],
      "source": [
        "# wandb.init(project=\"CS6910 - Assignment 1\", name=\"Question1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "_9_I2zTvq_K_",
        "outputId": "5c09b8b2-36e2-4879-dd99-54a74d8e1962"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Define class names\n",
        "className_images = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "trainingData_length=len(train_labels)\n",
        "total_class=max(train_labels)+1\n",
        "\n",
        "# print(trainingData_length)\n",
        "# print(y)\n",
        "\n",
        "#plotting images with its labels\n",
        "plt.figure(figsize=(5, 5))\n",
        "for i in range(total_class):\n",
        "    #subplot - used so that we can have many images in one image\n",
        "    # 1st row,2nd col, 3rd index of curr\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    sample_array = np.where(train_labels == i)\n",
        "    label_index=sample_array[0][0]\n",
        "    plt.imshow(train_images[label_index], cmap='gray')\n",
        "    plt.title(className_images[i])\n",
        "    plt.axis('off')\n",
        "    # wandb.log({\"Question1\": [wandb.Image(train_images[label_index], caption=className_images[i])]})\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "e04090ea27f94de7a864ec19bcc24a0f",
            "f50afc3441694398a5b2a0b2a77dbb5a",
            "38120d2c360d4183b486f9dde5077042",
            "422951a3b0714d37baa4fb0df1b9ce69",
            "546924928b084f1f8f184f4d268c84b6",
            "128e704b5b4e42dea9ed2019a2fd7fe2",
            "5b1199cacbab47c6a1b34884c8f49b3e",
            "5b2bb6d2d4fc4244a63b007f7d7f58a3"
          ]
        },
        "id": "wcGaM0lEu_09",
        "outputId": "4271cc60-0e9e-42c2-9c61-5c5903aca4e8"
      },
      "outputs": [],
      "source": [
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EhtQLwH05bp"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "0zruyo2P09Yb"
      },
      "outputs": [],
      "source": [
        "# wandb.init(project=\"CS6910 - Assignment 1\", name=\"Question2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18anNEnzDukV"
      },
      "source": [
        "# MultiLayerPerceptron_Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "1AFn3tVm2ByD"
      },
      "outputs": [],
      "source": [
        "class MultiLayerPerceptron():\n",
        "\n",
        "    def __init__(\n",
        "          self, \n",
        "          train_data, \n",
        "          train_labels, \n",
        "          layer_sizes,\n",
        "          initialization,\n",
        "          act_func,\n",
        "          loss_func,\n",
        "          batch_size=4,\n",
        "          epochs=1,\n",
        "          learning_rate=0.1,\n",
        "          weight_decay=0,\n",
        "          optimizer=\"sgd\",\n",
        "          momentum=0.5,\n",
        "          beta=0.5,\n",
        "          beta1=0.5,\n",
        "          beta2=0.5,  \n",
        "          epsilon=0.000001\n",
        "          ):\n",
        "\n",
        "        self.parameters = {}\n",
        "        self.gradients = {}\n",
        "        self.train_data = train_data\n",
        "        self.train_labels = train_labels\n",
        "        self.no_of_samples = len(train_data)\n",
        "        self.no_of_features = train_data.shape[1] #size of column of train_data\n",
        "        self.no_of_classes = 10 #size of column of train_labels\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.batch_size=batch_size\n",
        "        self.act_func=act_func\n",
        "        self.epochs=epochs\n",
        "        self.learning_rate=learning_rate\n",
        "        self.weight_decay=weight_decay\n",
        "        self.optimizer=optimizer\n",
        "        self.loss_func=loss_func\n",
        "        self.initialization = initialization\n",
        "        self.momentum=momentum\n",
        "        self.beta=beta\n",
        "        self.beta1=beta1\n",
        "        self.beta2=beta2\n",
        "        self.epsilon=epsilon\n",
        "\n",
        "        self.A = {}\n",
        "        self.H = {}       \n",
        "\n",
        "    def init_weights(self):\n",
        "      if self.initialization==\"random\":\n",
        "        # print(\"init random\")\n",
        "        for i in range(len(self.layer_sizes) - 1):\n",
        "            #input layer(n) and 1st hidden layer(m) will have weight vector w1->n*m and bias b1->1*m\n",
        "            #init W to random values\n",
        "            self.parameters[f'w_{i+1}'] = np.random.randn(self.layer_sizes[i], self.layer_sizes[i+1])\n",
        "            #init B to 0\n",
        "            self.parameters[f'b_{i+1}'] = np.random.randn(1,self.layer_sizes[i+1])\n",
        "\n",
        "      if self.initialization==\"Xavier\":\n",
        "        print(\"inint Xavier\")\n",
        "        for i in range(len(self.layer_sizes) - 1):\n",
        "          x_fact = np.sqrt(6 / (self.layer_sizes[i] + self.layer_sizes[i + 1]))\n",
        "          self.parameters[f'w_{i+1}'] = np.random.randn(self.layer_sizes[i], self.layer_sizes[i + 1]) * x_fact\n",
        "          self.parameters[f'b_{i+1}'] = np.random.randn(1,self.layer_sizes[i+1]) * x_fact\n",
        "\n",
        "    def softmax(self, x):\n",
        "      exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "      return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "    def softmax_d(self,x):\n",
        "      softmax_x = self.softmax(x)\n",
        "      return softmax_x*(1-softmax_x)\n",
        "\n",
        "    def feed_forwards(self, input_data):\n",
        "\n",
        "        # self.H[0]=input_data\n",
        "        for i in range(len(self.layer_sizes) - 1): # i -> 0-3\n",
        "            # if(i==0) :#input is our images\n",
        "            if(i==0):\n",
        "              self.A[i+1]=np.dot(input_data , self.parameters[f'w_{i+1}']) + self.parameters[f'b_{i+1}']\n",
        "            else:\n",
        "              self.A[i+1] = np.dot(self.H[i], self.parameters[f'w_{i+1}']) + self.parameters[f'b_{i+1}']\n",
        "\n",
        "            if i < len(self.layer_sizes) - 2 : # i < 3\n",
        "                self.H[i+1] = self.act_func.activation_func(self.A[i+1])\n",
        "            else :\n",
        "                self.H[i+1]=self.softmax(self.A[i+1])\n",
        "\n",
        "        return self.H[len(self.layer_sizes)-1]\n",
        "\n",
        "\n",
        "    def back_prop(self, input_data, true_label,y_pred):\n",
        "        # print(\"in back\")\n",
        "        if ((self.loss_func).get_name()==\"cross_entropy\"):\n",
        "          # print(\"cross_entropy\")\n",
        "          dL_dA = y_pred - true_label\n",
        "        elif ((self.loss_func).get_name()==\"mean_squared_error\"):\n",
        "          dL_dA = ((y_pred - true_label) * self.softmax_d(self.A[len(self.layer_sizes)-1])) / true_label.shape[0]\n",
        "\n",
        "        for i in range(len(self.layer_sizes) - 1, 1, -1): # i->4 3 2\n",
        "\n",
        "            self.gradients[f'w_{i}']=np.dot(self.H[i-1].T, dL_dA)\n",
        "            self.gradients[f'b_{i}']=np.sum(dL_dA , axis=0,keepdims=True)\n",
        "\n",
        "            dL_dH=np.dot(dL_dA, (self.parameters[f'w_{i}']).T )\n",
        "            dL_dA = dL_dH * self.act_func.derivation_of_activation(self.A[i-1])\n",
        "\n",
        "        self.gradients[f'w_{1}']=np.dot(input_data.T, dL_dA )\n",
        "        self.gradients[f'b_{1}']=np.sum(dL_dA , axis=0,keepdims=True)\n",
        "\n",
        "    def optimizer_func(self):\n",
        "        \n",
        "        if(self.optimizer==\"sgd\"):\n",
        "            #this is batch gradient descent or SGD\n",
        "            # no_of_batches = self.no_of_samples // batch_size\n",
        "            for i in range(self.epochs):\n",
        "                for j in range(0,self.no_of_samples,self.batch_size):\n",
        "                    start = j\n",
        "                    end = start + self.batch_size\n",
        "                    Y_train = self.train_labels[start:end]\n",
        "                    X_train = self.train_data[start:end]\n",
        "\n",
        "                    y_pred=self.feed_forwards(X_train)\n",
        "                    # y_pred=self.fprg(X_train)\n",
        "                    self.back_prop(X_train, Y_train,y_pred)\n",
        "\n",
        "                    for k in range(4):# 0->3\n",
        "                        self.gradients[f'w_{k+1}']=self.gradients[f'w_{k+1}']/self.batch_size\n",
        "                        self.gradients[f'b_{k+1}']=self.gradients[f'b_{k+1}']/self.batch_size\n",
        "\n",
        "                        self.gradients[f'w_{k+1}'] =(self.gradients[f'w_{k+1}']) + self.weight_decay * self.parameters[f'w_{k+1}']\n",
        "                        self.parameters[f'w_{k+1}'] -= self.learning_rate * (self.gradients[f'w_{k+1}'] )\n",
        "                        self.parameters[f'b_{k+1}'] -= self.learning_rate * (self.gradients[f'b_{k+1}'] )\n",
        "\n",
        "                loss,acc=self.loss_accuracy(self.train_data,self.train_labels)\n",
        "                print(f\"Epoch {i+1}, Loss: {loss} Acc: {acc}\")\n",
        "                # wandb.log({\"Epoch {i+1}, Loss: {loss} Acc: {acc}\"})\n",
        "\n",
        "        if(self.optimizer==\"momentum\"):\n",
        "          '''\n",
        "          Epoch 10, Loss: 0.6812374987038496 Acc: 75.0\n",
        "          TEST LOSS: 0.7075 ACCURACY: 72.0900\n",
        "          '''\n",
        "          velocities={}\n",
        "          for i in range(len(self.layer_sizes) - 1):            \n",
        "            velocities[f'w_{i+1}'] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))            \n",
        "            velocities[f'b_{i+1}'] = np.zeros((1, self.layer_sizes[i+1]))\n",
        "\n",
        "          for i in range(self.epochs):\n",
        "            for j in range(0,self.no_of_samples,self.batch_size):\n",
        "              start = j\n",
        "              end = start + self.batch_size\n",
        "              Y_train = self.train_labels[start:end]\n",
        "              X_train = self.train_data[start:end]\n",
        "\n",
        "              y_pred=self.feed_forwards(X_train)\n",
        "              self.back_prop(X_train, Y_train,y_pred)\n",
        "          \n",
        "              for k in range(len(self.layer_sizes) - 1):\n",
        "                  self.gradients[f'w_{k+1}']=self.gradients[f'w_{k+1}']/self.batch_size\n",
        "                  self.gradients[f'b_{k+1}']=self.gradients[f'b_{k+1}']/self.batch_size\n",
        "\n",
        "                  self.gradients[f'w_{k+1}'] =(self.gradients[f'w_{k+1}']) + self.weight_decay * self.parameters[f'w_{k+1}']\n",
        "                  # Update velocities with momentum\n",
        "                  velocities[f'w_{k+1}'] = self.momentum * velocities[f'w_{k+1}'] + self.learning_rate * (self.gradients[f'w_{k+1}'])\n",
        "                  velocities[f'b_{k+1}'] = self.momentum * velocities[f'b_{k+1}'] + self.learning_rate * (self.gradients[f'b_{k+1}'])\n",
        "\n",
        "                  # Update parameters with momentum\n",
        "                  self.parameters[f'w_{k+1}'] -= velocities[f'w_{k+1}']\n",
        "                  self.parameters[f'b_{k+1}'] -= velocities[f'b_{k+1}']\n",
        "\n",
        "            loss,acc=self.loss_accuracy(self.train_data,self.train_labels)\n",
        "            print(f\"Epoch {i+1}, Loss: {loss} Acc: {acc}\")\n",
        "\n",
        "        if(self.optimizer==\"nag\"):\n",
        "            '''\n",
        "            Epoch 100, Loss: 0.8561739933889985 Acc: 63.355\n",
        "            TEST LOSS: 0.8864 ACCURACY: 62.7400\n",
        "\n",
        "            Epoch 20, Loss: 1.013375573148102 Acc: 61.795\n",
        "            TEST LOSS: 1.0499 ACCURACY: 60.2300            \n",
        "            '''\n",
        "           # Initialize velocities for weights and biases\n",
        "            velocities={}\n",
        "            for i in range(len(self.layer_sizes) - 1):            \n",
        "                velocities[f'w_{i+1}'] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))            \n",
        "                velocities[f'b_{i+1}'] = np.zeros((1, self.layer_sizes[i+1]))\n",
        "\n",
        "            for i in range(self.epochs):\n",
        "                for j in range(0,self.no_of_samples,self.batch_size):\n",
        "                    start = j\n",
        "                    end = start + self.batch_size\n",
        "                    Y_train = self.train_labels[start:end]\n",
        "                    X_train = self.train_data[start:end]\n",
        "\n",
        "                    '''\n",
        "                    storing old weights in self.parameters[f'w_{k+1}_orig']\n",
        "                    so that i can use it later and \n",
        "                    updating self.parameters[f'w_{k+1}'] so that same feed forward function can be used.                \n",
        "                    '''\n",
        "                    for k in range(len(self.layer_sizes) - 1):\n",
        "                        self.parameters[f'w_{k+1}_orig']=self.parameters[f'w_{k+1}']\n",
        "                        self.parameters[f'b_{k+1}_orig']=self.parameters[f'b_{k+1}']\n",
        "\n",
        "                        self.parameters[f'w_{k+1}'] = self.parameters[f'w_{k+1}'] - momentum * velocities[f'w_{k+1}']\n",
        "                        self.parameters[f'b_{k+1}'] = self.parameters[f'b_{k+1}'] - momentum * velocities[f'b_{k+1}']\n",
        "                    \n",
        "                    #feed forward and backprop is applied after changing weights and biases\n",
        "                    y_pred=self.feed_forwards(X_train)\n",
        "                    self.back_prop(X_train, Y_train,y_pred)\n",
        "\n",
        "                    '''\n",
        "                    here 1st we will set original weights to self.parameters[f'w_{k+1}']\n",
        "                    and then update weigths and biases.\n",
        "                    '''\n",
        "                    for k in range(len(self.layer_sizes) - 1):\n",
        "\n",
        "                        self.gradients[f'w_{k+1}']=self.gradients[f'w_{k+1}']/self.batch_size\n",
        "                        self.gradients[f'b_{k+1}']=self.gradients[f'b_{k+1}']/self.batch_size\n",
        "\n",
        "                        self.gradients[f'w_{k+1}'] =(self.gradients[f'w_{k+1}']) + self.weight_decay * self.parameters[f'w_{k+1}']                        \n",
        "\n",
        "                        velocities[f'w_{k+1}'] = momentum * velocities[f'w_{k+1}'] + learning_rate * (self.gradients[f'w_{k+1}'] )\n",
        "                        velocities[f'b_{k+1}'] = momentum * velocities[f'b_{k+1}'] + learning_rate * (self.gradients[f'b_{k+1}'] )\n",
        "\n",
        "                        self.parameters[f'w_{k+1}']=self.parameters[f'w_{k+1}_orig']\n",
        "                        self.parameters[f'b_{k+1}']=self.parameters[f'b_{k+1}_orig']\n",
        "\n",
        "                        self.parameters[f'w_{k+1}'] -= velocities[f'w_{k+1}']\n",
        "                        self.parameters[f'b_{k+1}'] -= velocities[f'b_{k+1}']\n",
        "\n",
        "                loss,acc=self.loss_accuracy(self.train_data,self.train_labels)\n",
        "                print(f\"Epoch {i+1}, Loss: {loss} Acc: {acc}\")\n",
        "\n",
        "        if(self.optimizer==\"rmsprop\"):\n",
        "          '''\n",
        "          Epoch 10, Loss: 0.6455246819185498 Acc: 75.41499999999999\n",
        "          TEST LOSS: 0.6710 ACCURACY: 74.4000\n",
        "          '''\n",
        "          squared_gradients={}\n",
        "          for i in range(len(self.layer_sizes) - 1):            \n",
        "              squared_gradients[f'w_{i+1}'] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))            \n",
        "              squared_gradients[f'b_{i+1}'] = np.zeros((1, self.layer_sizes[i+1]))\n",
        "\n",
        "          for i in range(self.epochs):\n",
        "              for j in range(0,self.no_of_samples,self.batch_size):\n",
        "                  start = j\n",
        "                  end = start + self.batch_size\n",
        "                  Y_train = self.train_labels[start:end]\n",
        "                  X_train = self.train_data[start:end]\n",
        "\n",
        "                  y_pred=self.feed_forwards(X_train)\n",
        "                  self.back_prop(X_train, Y_train,y_pred)\n",
        "\n",
        "                  for k in range(len(self.layer_sizes) - 1):\n",
        "\n",
        "                      self.gradients[f'w_{k+1}']=self.gradients[f'w_{k+1}']/self.batch_size\n",
        "                      self.gradients[f'b_{k+1}']=self.gradients[f'b_{k+1}']/self.batch_size\n",
        "\n",
        "                      self.gradients[f'w_{k+1}'] =(self.gradients[f'w_{k+1}']) + self.weight_decay * self.parameters[f'w_{k+1}']                        \n",
        "\n",
        "                      # Calculate the squared gradients\n",
        "                      squared_gradients[f'w_{k+1}'] = self.beta * squared_gradients[f'w_{k+1}'] + (1 - self.beta) * ((self.gradients[f'w_{k+1}']) ** 2)\n",
        "                      squared_gradients[f'b_{k+1}'] = self.beta * squared_gradients[f'b_{k+1}'] + (1 - self.beta) * ((self.gradients[f'b_{k+1}']) ** 2)\n",
        "\n",
        "                      # Update parameters using RMSprop\n",
        "                      self.parameters[f'w_{k+1}'] -= (self.learning_rate * self.gradients[f'w_{k+1}'] / (np.sqrt(squared_gradients[f'w_{k+1}']) + self.epsilon))\n",
        "                      self.parameters[f'b_{k+1}'] -= (self.learning_rate * self.gradients[f'b_{k+1}'] / (np.sqrt(squared_gradients[f'b_{k+1}']) + self.epsilon))\n",
        "\n",
        "              loss,acc=self.loss_accuracy(self.train_data,self.train_labels)\n",
        "              print(f\"Epoch {i+1}, Loss: {loss} Acc: {acc}\")\n",
        "\n",
        "        if(self.optimizer==\"adam\"):\n",
        "          '''\n",
        "          Epoch 10, Loss: 0.6223362734184407 Acc: 77.985\n",
        "          TEST LOSS: 0.6613 ACCURACY: 76.2700\n",
        "          '''\n",
        "          moments={}\n",
        "          for i in range(len(self.layer_sizes) - 1):            \n",
        "              moments[f'm_w_{i+1}'] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))            \n",
        "              moments[f'm_b_{i+1}'] = np.zeros((1, self.layer_sizes[i+1]))\n",
        "\n",
        "          velocities={}\n",
        "          for i in range(len(self.layer_sizes) - 1):            \n",
        "              velocities[f'v_w_{i+1}'] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))            \n",
        "              velocities[f'v_b_{i+1}'] = np.zeros((1, self.layer_sizes[i+1]))\n",
        "\n",
        "          \n",
        "          for i in range(self.epochs):\n",
        "            for j in range(0,self.no_of_samples,self.batch_size):\n",
        "                start = j\n",
        "                end = start + self.batch_size\n",
        "                Y_train = self.train_labels[start:end]\n",
        "                X_train = self.train_data[start:end]\n",
        "\n",
        "                y_pred=self.feed_forwards(X_train)\n",
        "                self.back_prop(X_train, Y_train,y_pred)\n",
        "                t=1\n",
        "                for k in range(len(self.layer_sizes) - 1):\n",
        "\n",
        "                    self.gradients[f'w_{k+1}'] = self.gradients[f'w_{k+1}'] / self.batch_size\n",
        "                    self.gradients[f'b_{k+1}']=self.gradients[f'b_{k+1}']/self.batch_size\n",
        "\n",
        "                    self.gradients[f'w_{k+1}'] = self.gradients[f'w_{k+1}'] + self.weight_decay * self.parameters[f'w_{k+1}']\n",
        "\n",
        "                    # Update moments and velocities with Adam\n",
        "                    moments[f'm_w_{k+1}'] = self.beta1 * moments[f'm_w_{k+1}'] + (1 - self.beta1) * self.gradients[f'w_{k+1}']\n",
        "                    moments[f'm_b_{k+1}'] = self.beta1 * moments[f'm_b_{k+1}'] + (1 - self.beta1) * self.gradients[f'b_{k+1}']\n",
        "\n",
        "                    velocities[f'v_w_{k+1}'] = self.beta2 * velocities[f'v_w_{k+1}'] + (1 - self.beta2) * (self.gradients[f'w_{k+1}'] ** 2)\n",
        "                    velocities[f'v_b_{k+1}'] = self.beta2 * velocities[f'v_b_{k+1}'] + (1 - self.beta2) * (self.gradients[f'b_{k+1}'] ** 2)\n",
        "\n",
        "                    # Bias correction\n",
        "                    m_w_hat = moments[f'm_w_{k+1}'] / (1 - self.beta1 ** t)\n",
        "                    m_b_hat = moments[f'm_b_{k+1}'] / (1 - self.beta1 ** t)\n",
        "\n",
        "                    v_w_hat = velocities[f'v_w_{k+1}'] / (1 - self.beta2 ** t)\n",
        "                    v_b_hat = velocities[f'v_b_{k+1}'] / (1 - self.beta2 ** t)\n",
        "\n",
        "                    # Update parameters with Adam\n",
        "                    self.parameters[f'w_{k+1}'] -= self.learning_rate * m_w_hat / (np.sqrt(v_w_hat) + self.epsilon)\n",
        "                    self.parameters[f'b_{k+1}'] -= self.learning_rate * m_b_hat / (np.sqrt(v_b_hat) + self.epsilon)\n",
        "\n",
        "                    t=t+1                \n",
        "\n",
        "            loss,acc=self.loss_accuracy(self.train_data,self.train_labels)\n",
        "            print(f\"Epoch {i+1}, Loss: {loss} Acc: {acc}\")\n",
        "\n",
        "        if(self.optimizer==\"nadam\"):\n",
        "          '''\n",
        "          Epoch 10, Loss: 0.645183860082157 Acc: 78.36333333333333\n",
        "          TEST LOSS: 0.6794 ACCURACY: 77.5300\n",
        "          '''\n",
        "          moments={}\n",
        "          for i in range(len(self.layer_sizes) - 1):            \n",
        "              moments[f'm_w_{i+1}'] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))            \n",
        "              moments[f'm_b_{i+1}'] = np.zeros((1, self.layer_sizes[i+1]))\n",
        "\n",
        "          velocities={}\n",
        "          for i in range(len(self.layer_sizes) - 1):            \n",
        "              velocities[f'v_w_{i+1}'] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))            \n",
        "              velocities[f'v_b_{i+1}'] = np.zeros((1, self.layer_sizes[i+1]))\n",
        "\n",
        "          t=1\n",
        "          for i in range(self.epochs):\n",
        "            for j in range(0,self.no_of_samples,self.batch_size):\n",
        "              start = j\n",
        "              end = start + self.batch_size\n",
        "              Y_train = self.train_labels[start:end]\n",
        "              X_train = self.train_data[start:end]\n",
        "\n",
        "              y_pred=self.feed_forwards(X_train)\n",
        "              self.back_prop(X_train, Y_train,y_pred)\n",
        "\n",
        "              for k in range(len(self.layer_sizes) - 1):\n",
        "\n",
        "                  self.gradients[f'w_{k+1}'] = self.gradients[f'w_{k+1}'] / self.batch_size\n",
        "                  self.gradients[f'b_{k+1}']=self.gradients[f'b_{k+1}']/self.batch_size\n",
        "\n",
        "                  self.gradients[f'w_{k+1}'] = self.gradients[f'w_{k+1}'] + self.weight_decay * self.parameters[f'w_{k+1}']\n",
        "\n",
        "                  # Update moments and velocities with Adam\n",
        "                  moments[f'm_w_{k+1}'] = self.beta1 * moments[f'm_w_{k+1}'] + (1 - self.beta1) * self.gradients[f'w_{k+1}']\n",
        "                  moments[f'm_b_{k+1}'] = self.beta1 * moments[f'm_b_{k+1}'] + (1 - self.beta1) * self.gradients[f'b_{k+1}']\n",
        "\n",
        "                  velocities[f'v_w_{k+1}'] = self.beta2 * velocities[f'v_w_{k+1}'] + (1 - self.beta2) * (self.gradients[f'w_{k+1}'] ** 2)\n",
        "                  velocities[f'v_b_{k+1}'] = self.beta2 * velocities[f'v_b_{k+1}'] + (1 - self.beta2) * (self.gradients[f'b_{k+1}'] ** 2)\n",
        "\n",
        "                  # Bias correction\n",
        "                  m_w_hat = moments[f'm_w_{k+1}'] / (1 - self.beta1 ** t)\n",
        "                  m_b_hat = moments[f'm_b_{k+1}'] / (1 - self.beta1 ** t)\n",
        "\n",
        "                  v_w_hat = velocities[f'v_w_{k+1}'] / (1 - self.beta2 ** t)\n",
        "                  v_b_hat = velocities[f'v_b_{k+1}'] / (1 - self.beta2 ** t)\n",
        "\n",
        "                  # Update parameters with NAdam\n",
        "                  nadam_factor = (1 - self.beta1) / (1 - (self.beta1 ** t))\n",
        "                  weigth_update = nadam_factor * self.gradients[f'w_{k+1}'] + (self.beta1 * m_w_hat)\n",
        "                  bias_update = nadam_factor * self.gradients[f'b_{k+1}'] + (self.beta1 * m_b_hat)\n",
        "                  self.parameters[f'w_{k+1}'] -= ((self.learning_rate / (np.sqrt(v_w_hat) + self.epsilon)) * weigth_update )\n",
        "                  self.parameters[f'b_{k+1}'] -= ((self.learning_rate / (np.sqrt(v_b_hat) + self.epsilon)) * bias_update )\n",
        "\n",
        "              t=t+1\n",
        "\n",
        "            loss,acc=self.loss_accuracy(self.train_data,self.train_labels)\n",
        "            print(f\"Epoch {i+1}, Loss: {loss} Acc: {acc}\")\n",
        "\n",
        "    def accuracy(self, pred, truth):\n",
        "      return (np.argmax(truth, axis=1) == np.argmax(pred, axis=1)).mean()\n",
        "\n",
        "    def test(self, x, y):\n",
        "      y_pred=self.feed_forwards(x)\n",
        "      loss = self.loss_func.loss_functions(y_pred, y)\n",
        "      acc = self.accuracy(y_pred, y)\n",
        "      print(f'TEST LOSS: {loss:.4f} ACCURACY: {acc*100:.4f}')\n",
        "\n",
        "    def loss_accuracy(self, input_data, true_values):\n",
        "\n",
        "        y_pred = self.feed_forwards(input_data)\n",
        "        accuracy = self.accuracy(y_pred,true_values)\n",
        "        loss = self.loss_func.loss_functions(y_pred, true_values)\n",
        "        return loss, accuracy*100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4psMsEqVIYH"
      },
      "source": [
        "# Loss_Func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "rdI2YZuoVNpl"
      },
      "outputs": [],
      "source": [
        "class LossFunc():\n",
        "    def __init__(self, fun = \"cross_entropy\"):\n",
        "        self.loss_func = fun\n",
        "\n",
        "    def loss_functions(self,pred, actual):\n",
        "      if (self.loss_func==\"cross_entropy\"):\n",
        "        return -np.sum(actual * np.log(pred + 1e-9)) / len(pred)\n",
        "\n",
        "      elif (self.loss_func == \"mean_squared_error\"):\n",
        "        return (1/2)* np.sum((pred - actual) ** 2) / len(pred)\n",
        "\n",
        "    def get_name(self):\n",
        "      if (self.loss_func==\"cross_entropy\"):\n",
        "        return \"cross_entropy\"\n",
        "\n",
        "      elif (self.loss_func == \"mean_squared_error\"):\n",
        "        return \"mean_squared_error\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eDi2ooGDWdc"
      },
      "source": [
        "# Activation Func Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "mX8q1aoq5kfA"
      },
      "outputs": [],
      "source": [
        "class ActivationFunctions():\n",
        "    def __init__(self, fun = \"sigmoid\"):\n",
        "        self.act_fun = fun\n",
        "\n",
        "    def activation_func(self, x):\n",
        "\n",
        "        if(self.act_fun == \"sigmoid\"):\n",
        "          # sigmoid function\n",
        "          sigmoid_x = np.zeros_like(x)\n",
        "          positive_mask = x >= 0\n",
        "          sigmoid_x[positive_mask] = 1.0 / (1.0 + np.exp(-x[positive_mask]))\n",
        "          sigmoid_x[~positive_mask] = np.exp(x[~positive_mask]) / (1.0 + np.exp(x[~positive_mask]))\n",
        "          return sigmoid_x\n",
        "\n",
        "        elif(self.act_fun == \"softmax\"):\n",
        "          # softmax function\n",
        "          exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "          return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "        elif(self.act_fun == \"tanh\"):\n",
        "            # tanh function\n",
        "            return np.tanh(x)\n",
        "\n",
        "        elif(self.act_fun == \"ReLU\"):\n",
        "          # relu function\n",
        "          return np.maximum(0, x)\n",
        "\n",
        "    def derivation_of_activation(self, x):\n",
        "\n",
        "        if(self.act_fun == \"sigmoid\"):\n",
        "          sigmoid_x = self.activation_func(x)\n",
        "          return sigmoid_x * (1 - sigmoid_x)\n",
        "\n",
        "        if(self.act_fun == \"softmax\"):\n",
        "            softmax_x = self.activation_func(x)\n",
        "            return softmax_x*(1-softmax_x)\n",
        "\n",
        "        if(self.act_fun == \"tanh\"):\n",
        "            return 1 - (np.tanh(x) ** 2)\n",
        "\n",
        "        if(self.act_fun == \"ReLU\"):\n",
        "          return (x > 0) * 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj-jL6XUDdC7"
      },
      "source": [
        "# Load_Process_Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "4ZDLoDQP3IEH"
      },
      "outputs": [],
      "source": [
        "#Load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "total_class=max(train_labels)\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], -1) / 255.0\n",
        "test_images = test_images.reshape(test_images.shape[0], -1) / 255.0\n",
        "\n",
        "#change trainlabel=2 to oneHot=[0 0 1 0 0 0 0 0 0 0]\n",
        "train_labels_one_hot = np.eye(10)[train_labels]\n",
        "test_labels_one_hot = np.eye(10)[test_labels]\n",
        "\n",
        "train_images, val_images, train_labels_one_hot, val_labels_one_hot = train_test_split(train_images, train_labels_one_hot, test_size=0.1, random_state=42)\n",
        "\n",
        "layer_sizes = [train_images.shape[1],5,10,15,10]  # Input, hidden1, hidden2,hidden3 output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdhI_vxHDk63"
      },
      "source": [
        "# Set_Call_Fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZsm2fOr3L6Y",
        "outputId": "29cb829d-7242-4b22-8e81-e66cc2266504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inint Xavier\n",
            "Epoch 1, Loss: 0.2913724775613862 Acc: 60.405\n",
            "Epoch 2, Loss: 0.23312698618335262 Acc: 73.71333333333332\n",
            "Epoch 3, Loss: 0.18315244412398998 Acc: 77.59666666666666\n",
            "Epoch 4, Loss: 0.1566211527565627 Acc: 80.21666666666667\n",
            "Epoch 5, Loss: 0.14517062214250792 Acc: 80.94666666666667\n",
            "Epoch 6, Loss: 0.1392168781547627 Acc: 81.65833333333333\n",
            "Epoch 7, Loss: 0.13677342721298505 Acc: 81.93\n",
            "Epoch 8, Loss: 0.13322195629868083 Acc: 82.44\n",
            "Epoch 9, Loss: 0.13075228273753878 Acc: 82.71666666666667\n",
            "Epoch 10, Loss: 0.12893759075665345 Acc: 82.96\n",
            "TEST LOSS: 0.1411 ACCURACY: 81.3500\n"
          ]
        }
      ],
      "source": [
        "act_func = ActivationFunctions(\"sigmoid\") # sigmoid, ReLU, tanh\n",
        "loss_func = LossFunc(\"mean_squared_error\") #\"mean_squared_error\", \"cross_entropy\"\n",
        "epochs=10\n",
        "initialization=\"Xavier\" #random , Xavier\n",
        "learning_rate=0.001\n",
        "momentum=0.9  #for momentum and nag\n",
        "beta=0.9     #for rmsprop\n",
        "beta1=0.9    #for adam and nadam\n",
        "beta2=0.999    #for adam and nadam\n",
        "epsilon=0.000001\n",
        "weight_decay=0\n",
        "batch_size=32\n",
        "optimizer=\"adam\" # sgd , momentum ,nag , rmsprop , adam , nadam \n",
        "\n",
        "mlp = MultiLayerPerceptron(train_images, train_labels_one_hot, layer_sizes,initialization,act_func,loss_func,batch_size,epochs,learning_rate,weight_decay,optimizer,momentum)\n",
        "mlp.init_weights()\n",
        "mlp.optimizer_func()\n",
        "mlp.test(test_images, test_labels_one_hot)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "128e704b5b4e42dea9ed2019a2fd7fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38120d2c360d4183b486f9dde5077042": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b1199cacbab47c6a1b34884c8f49b3e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b2bb6d2d4fc4244a63b007f7d7f58a3",
            "value": 1
          }
        },
        "422951a3b0714d37baa4fb0df1b9ce69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546924928b084f1f8f184f4d268c84b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b1199cacbab47c6a1b34884c8f49b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b2bb6d2d4fc4244a63b007f7d7f58a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e04090ea27f94de7a864ec19bcc24a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f50afc3441694398a5b2a0b2a77dbb5a",
              "IPY_MODEL_38120d2c360d4183b486f9dde5077042"
            ],
            "layout": "IPY_MODEL_422951a3b0714d37baa4fb0df1b9ce69"
          }
        },
        "f50afc3441694398a5b2a0b2a77dbb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546924928b084f1f8f184f4d268c84b6",
            "placeholder": "​",
            "style": "IPY_MODEL_128e704b5b4e42dea9ed2019a2fd7fe2",
            "value": "0.016 MB of 0.016 MB uploaded\r"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
